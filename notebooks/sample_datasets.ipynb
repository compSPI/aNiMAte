{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcb4e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import starfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mrcfile\n",
    "from tqdm import tqdm\n",
    "import configargparse\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "module_path = os.path.abspath(os.path.join('../src/experiment_scripts'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from aNiMAte.src.experiment_scripts.main import init_config\n",
    "from aNiMAte.src.atomic_utils import AtomicModel\n",
    "from aNiMAte.src.prody_utils import read_prody_model\n",
    "from aNiMAte.src.dynamics_utils import DynamicsModelNMA\n",
    "from prody import *\n",
    "import pykeops\n",
    "\n",
    "DATA_PATH = '/sdf/group/ml/CryoNet/experiments/ake/simulated/'\n",
    "CONFIG_PATH =  '/sdf/group/ml/CryoNet/train_configs/ak-atomic-primal-sim.ini'\n",
    "PDB_PATH = '/sdf/group/ml/CryoNet/experiments/ake/simulated/models/frames/'\n",
    "START_PDB = os.path.join(PDB_PATH, 'new_frame00.pdb')\n",
    "DATASET_NUM = 50\n",
    "MAX_NUM_MODES = 128\n",
    "pykeops.set_verbose(False)\n",
    "\n",
    "def populate_starfile_list():\n",
    "    parser = configargparse.ArgParser()\n",
    "    parser.add_argument('-c', '--config', required=False, is_config_file=True,\n",
    "                        help='Path to config file.', default=CONFIG_PATH)\n",
    "    parser.add_argument(\"-f\", \"--fff\", help=\"a dummy argument to fool ipython\", default=\"1\")\n",
    "    init_config(parser)  # use the default arguments from main.init_config to stay synchronized\n",
    "    config = parser.parse_args()\n",
    "    atomic_model = AtomicModel(START_PDB, config.atomic_clean_pdb, config.atomic_center,\n",
    "                                   pdb_out=os.path.join('.', 'curated_gemmi.pdb'))\n",
    "    prody_model = read_prody_model('curated_gemmi.pdb')\n",
    "    atoms1 = prody_model.getCoords().reshape((-1, 1))\n",
    "    num_atoms = prody_model.getCoords().shape[0]\n",
    "    atomic_model = DynamicsModelNMA(atomic_model, atomic_clean_pdb=config.atomic_clean_pdb,\n",
    "                                atomic_cg_selection=config.atomic_cg_selection,\n",
    "                                atomic_nma_cutoff=config.atomic_nma_cutoff,\n",
    "                                atomic_nma_gamma=config.atomic_nma_gamma,\n",
    "                                atomic_nma_number_modes=MAX_NUM_MODES,\n",
    "                                by_chain=config.atomic_nma_by_chain)\n",
    "    eigvecs = atomic_model.eigvecs.detach().cpu().numpy()\n",
    "    eigvals = atomic_model.eigvals.detach().cpu().numpy()\n",
    "    Q = eigvecs.reshape((-1, MAX_NUM_MODES))\n",
    "    S = np.matmul(Q , np.diag(1./eigvals))\n",
    "    Q, _, _ = np.linalg.svd(S, full_matrices=False) \n",
    "\n",
    "    dataset_starfiles = []\n",
    "    for i in range(DATASET_NUM):\n",
    "        target_pdb = os.path.join(PDB_PATH, 'new_frame%02d.pdb'%(i+1))\n",
    "        atomic_model2 = AtomicModel(target_pdb, config.atomic_clean_pdb, config.atomic_center,\n",
    "                                       pdb_out=os.path.join('.', 'curated_gemmi.pdb'))\n",
    "        prody_model2 = read_prody_model('curated_gemmi.pdb');\n",
    "        atoms2 = prody_model2.getCoords().reshape((-1, 1))\n",
    "        coord_diff = atoms2 - atoms1\n",
    "        alphas = np.squeeze(np.matmul(Q.T, coord_diff))\n",
    "        dataset_path = os.path.join(DATA_PATH, 'new_frame%02d'%(i+1))\n",
    "        dataset_starfiles.append({'starfile': starfile.read(os.path.join(dataset_path, 'new_frame%02d.star'%(i+1))),\n",
    "                                  'dataset_path': dataset_path, 'alphas': alphas})\n",
    "    return dataset_starfiles\n",
    "\n",
    "def get_filename(step, n_char=6):\n",
    "    if step == 0:\n",
    "        return '0' * n_char\n",
    "    else:\n",
    "        n_dec = int(np.log10(step))\n",
    "        return '0' * (n_char - n_dec) + str(step)\n",
    "\n",
    "def write_sampled_dataset(dataset_name, dataset_indeces, batch_size=250):\n",
    "    data_out_path = os.path.join(DATA_PATH, dataset_name)\n",
    "    out_particles_num = len(dataset_indeces)\n",
    "    dataset_starfiles = populate_starfile_list()\n",
    "    out_starfile = {'optics': dataset_starfiles[0]['starfile']['optics'], \n",
    "                    'particles': pd.DataFrame(columns = dataset_starfiles[0]['starfile']['particles'].columns)}\n",
    "    S = dataset_starfiles[0]['starfile']['optics']['rlnImageSize'][0]\n",
    "    mrcs_path = os.path.join(data_out_path, 'Particles/')\n",
    "    if not os.path.exists(mrcs_path):\n",
    "        os.makedirs(mrcs_path)\n",
    "    mrc_index = 0\n",
    "    for i, dataset_index in enumerate(tqdm(dataset_indeces)):\n",
    "        if i % batch_size == 0:\n",
    "            findex = get_filename((i//batch_size)+1, n_char=6)\n",
    "            mrc_relative_path = f'Particles/particles_{findex}.mrcs'\n",
    "            mrcs_file = os.path.join(data_out_path, mrc_relative_path)\n",
    "            mrc = mrcfile.new_mmap(mrcs_file, \n",
    "                                   shape=(batch_size, S, S), \n",
    "                                   mrc_mode=2, overwrite=True)\n",
    "            mrc_index = 0\n",
    "        particle_row = dataset_starfiles[dataset_index]['starfile']['particles'].iloc[[0]]\n",
    "        imgnamedf = particle_row['rlnImageName'].values[0].split('@')\n",
    "        in_mrc_path = os.path.join(dataset_starfiles[dataset_index]['dataset_path'], imgnamedf[1])\n",
    "        pidx = int(imgnamedf[0]) - 1\n",
    "        with mrcfile.mmap(in_mrc_path, mode='r', permissive=True) as f:\n",
    "            mrc.data[mrc_index] = f.data[pidx]\n",
    "            mrc_index += 1\n",
    "        particle_row['rlnImageName'] = get_filename(mrc_index, n_char=6) + '@' + mrc_relative_path\n",
    "        particle_row['nmaAlphas'] = ','.join(['%.5f' % num for num in dataset_starfiles[dataset_index]['alphas']])\n",
    "        particle_row['pdbIndex'] = dataset_index + 1\n",
    "        dataset_starfiles[dataset_index]['starfile']['particles'] = dataset_starfiles[dataset_index]['starfile']['particles'].iloc[1: , :]\n",
    "        out_starfile['particles'] = pd.concat([out_starfile['particles'], particle_row])\n",
    "\n",
    "    out_starfile['particles'].reset_index(drop=True, inplace=True)\n",
    "    starfile.write(out_starfile, os.path.join(data_out_path, f'{dataset_name}.star'), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f200bc86",
   "metadata": {},
   "source": [
    "### Generate Uniform Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224483e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_PARTICLES_NUM = 50000\n",
    "dataset_indeces = np.random.choice(np.arange(DATASET_NUM), OUT_PARTICLES_NUM)\n",
    "plt.figure()\n",
    "plt.hist(dataset_indeces, bins=DATASET_NUM);\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Particles')\n",
    "\n",
    "write_sampled_dataset('uniform', dataset_indeces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e5f0a7",
   "metadata": {},
   "source": [
    "### Discontinuous Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363ef398",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_PARTICLES_NUM = 50000\n",
    "EPS = 1e-6\n",
    "\n",
    "means = np.random.choice([1, 2, 3], size = OUT_PARTICLES_NUM)\n",
    "stdevs = np.random.choice([0.05], size = OUT_PARTICLES_NUM)\n",
    "dataset_indeces = np.random.normal(loc=means, scale=stdevs)\n",
    "dataset_indeces -= dataset_indeces.min()\n",
    "dataset_indeces /= (dataset_indeces.max() + EPS)\n",
    "dataset_indeces *= DATASET_NUM\n",
    "dataset_indeces = np.floor(dataset_indeces).astype(int)\n",
    "plt.figure()\n",
    "plt.hist(dataset_indeces, bins=DATASET_NUM);\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Particles')\n",
    "\n",
    "write_sampled_dataset('discontinuous', dataset_indeces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cf832c",
   "metadata": {},
   "source": [
    "### Continuous Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f32474",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_PARTICLES_NUM = 50000\n",
    "EPS = 1e-6\n",
    "\n",
    "means = np.random.choice([1, 2, 3], size = OUT_PARTICLES_NUM)\n",
    "stdevs = np.random.choice([0.25], size = OUT_PARTICLES_NUM)\n",
    "dataset_indeces = np.random.normal(loc=means, scale=stdevs)\n",
    "dataset_indeces -= dataset_indeces.min()\n",
    "dataset_indeces /= (dataset_indeces.max() + EPS)\n",
    "dataset_indeces *= DATASET_NUM\n",
    "dataset_indeces = np.floor(dataset_indeces).astype(int)\n",
    "plt.figure()\n",
    "plt.hist(dataset_indeces, bins=DATASET_NUM);\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Particles')\n",
    "\n",
    "write_sampled_dataset('continuous', dataset_indeces)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}